{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srishticodes/Dataanalysis/blob/main/fuzzycmeansproblem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a python code to read a data sample (csv file). Next initialize a\n",
        "membership matrix, and cluster the data samples using soft clustering\n",
        "technique having level of fuzziness as 1.26 and c=2 (without using inbuilt\n",
        "methods)"
      ],
      "metadata": {
        "id": "QT8q_b0K-YhC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW68T96F5Gd9",
        "outputId": "712ddaa8-606c-4861-d6d6-66aaabb980f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged in 52 iterations\n",
            "Cluster centers:\n",
            "[75.49453423252312, 5.919486560801025, 2.7785139814662627, 4.240843239500129, 1.322071003060998]\n",
            "[25.212680404038828, 5.028343236162345, 3.413251508700955, 1.5065870772834362, 0.26081739297181766]\n",
            "[125.78705081886477, 6.5813241049058595, 2.9696473503595606, 5.523762024550332, 2.011024053386354]\n",
            "\n",
            "First five membership rows:\n",
            "[0.00017472872861289452, 0.9998219625164851, 3.308754901819003e-06]\n",
            "[0.00014031935848416756, 0.9998571330788445, 2.547562671222458e-06]\n",
            "[0.00011101487594724314, 0.9998870533528978, 1.9317711550955415e-06]\n",
            "[8.679586046628348e-05, 0.9999117590938873, 1.4450456463746619e-06]\n",
            "[6.656036073936304e-05, 0.9999323797868648, 1.0598523960812642e-06]\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import random\n",
        "import math\n",
        "import urllib.request\n",
        "import io\n",
        "\n",
        "def load_data(filepath):\n",
        "    \"\"\"\n",
        "    Read numeric data from a CSV file and return as a list of lists of floats.\n",
        "    Assumes first row is header.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "\n",
        "    # Handle both local and URL CSVs\n",
        "    if filepath.startswith(\"http\"):\n",
        "        response = urllib.request.urlopen(filepath)\n",
        "        f = io.StringIO(response.read().decode('utf-8'))\n",
        "    else:\n",
        "        f = open(filepath, newline='')\n",
        "\n",
        "    reader = csv.reader(f)\n",
        "    headers = next(reader)  # skip header\n",
        "    for row in reader:\n",
        "        # Skip non-numeric columns like \"Species\" in Iris dataset\n",
        "        try:\n",
        "            data.append([float(val) for val in row if val.replace('.', '', 1).isdigit()])\n",
        "        except ValueError:\n",
        "            continue\n",
        "    return data\n",
        "\n",
        "def initialize_membership(n_samples, c=2):\n",
        "    \"\"\"\n",
        "    Initialize U as an n_samples x c matrix with each row summing to 1,\n",
        "    using uniform random numbers.\n",
        "    \"\"\"\n",
        "    U = []\n",
        "    for _ in range(n_samples):\n",
        "        u = [random.random() for _ in range(c)]\n",
        "        s = sum(u)\n",
        "        U.append([val / s for val in u])\n",
        "    return U\n",
        "\n",
        "def compute_centroids(data, U, m=1.26):\n",
        "    \"\"\"\n",
        "    Compute centroids using fuzzy memberships.\n",
        "    \"\"\"\n",
        "    n_samples = len(data)\n",
        "    n_features = len(data[0])\n",
        "    c = len(U[0])\n",
        "    centroids = [[0.0] * n_features for _ in range(c)]\n",
        "\n",
        "    for j in range(c):\n",
        "        num = [0.0] * n_features\n",
        "        den = 0.0\n",
        "        for i in range(n_samples):\n",
        "            weight = U[i][j] ** m\n",
        "            den += weight\n",
        "            for d in range(n_features):\n",
        "                num[d] += weight * data[i][d]\n",
        "        centroids[j] = [num[d] / den for d in range(n_features)]\n",
        "    return centroids\n",
        "\n",
        "def update_membership(data, centroids, m=1.26):\n",
        "    \"\"\"\n",
        "    Update the membership matrix U.\n",
        "    \"\"\"\n",
        "    n_samples = len(data)\n",
        "    c = len(centroids)\n",
        "    U_new = [[0.0] * c for _ in range(n_samples)]\n",
        "    exponent = 2.0 / (m - 1.0)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        dists = []\n",
        "        for j in range(c):\n",
        "            dist = math.sqrt(sum(\n",
        "                (data[i][d] - centroids[j][d]) ** 2\n",
        "                for d in range(len(data[0]))\n",
        "            ))\n",
        "            dists.append(dist if dist > 1e-12 else 1e-12)\n",
        "\n",
        "        for j in range(c):\n",
        "            denom = sum((dists[j] / dists[k]) ** exponent for k in range(c))\n",
        "            U_new[i][j] = 1.0 / denom\n",
        "    return U_new\n",
        "\n",
        "def fuzzy_c_means(filepath, c=2, m=1.26, epsilon=1e-5, max_iter=100):\n",
        "    \"\"\"\n",
        "    Perform Fuzzy C-Means clustering.\n",
        "    \"\"\"\n",
        "    data = load_data(filepath)\n",
        "    n_samples = len(data)\n",
        "    U = initialize_membership(n_samples, c)\n",
        "\n",
        "    for iteration in range(max_iter):\n",
        "        U_prev = [row[:] for row in U]\n",
        "        centroids = compute_centroids(data, U, m)\n",
        "        U = update_membership(data, centroids, m)\n",
        "\n",
        "        diff = sum(\n",
        "            abs(U[i][j] - U_prev[i][j])\n",
        "            for i in range(n_samples)\n",
        "            for j in range(c)\n",
        "        )\n",
        "        if diff < epsilon:\n",
        "            print(f\"Converged in {iteration + 1} iterations\")\n",
        "            break\n",
        "\n",
        "    return centroids, U\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    csv_path = \"\"/kaggle/input/iris/Iris.csv\"\"\n",
        "    centers, membership = fuzzy_c_means(csv_path, c=3)\n",
        "    print(\"Cluster centers:\")\n",
        "    for center in centers:\n",
        "        print(center)\n",
        "    print(\"\\nFirst five membership rows:\")\n",
        "    for row in membership[:5]:\n",
        "        print(row)\n"
      ]
    }
  ]
}